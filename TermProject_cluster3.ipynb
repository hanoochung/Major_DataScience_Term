{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.core.display_functions import display\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./data/COVID-19-Constructed-Dataset-(PANEL).xlsx\")  #read csv file and store in df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Preprocessing\n",
    "### 3-1. Categorical Data change to Numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Categorical Data change to Numeric Data\n",
    "# 0 = Female, 1 = Male\n",
    "encoder = OrdinalEncoder(dtype=np.int64)\n",
    "X = pd.DataFrame(df['gender'])\n",
    "encoder.fit(X)\n",
    "\n",
    "# Deep copy\n",
    "data_select = df.copy()\n",
    "data_select['gender'] = pd.DataFrame(encoder.transform(X))\n",
    "\n",
    "# Verify the data has been changed appropriately\n",
    "data_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# timeperiod column name change 'online'\n",
    "# divide online , NotOnline\n",
    "# 0 = notOnline, 1 = online\n",
    "for i in range(len(data_select)):\n",
    "    sumOnline = 0\n",
    "    sumNonOnline = 0\n",
    "    if data_select.loc[i, 'timeperiod'] < 3:\n",
    "        data_select.loc[i, 'timeperiod'] = 0\n",
    "    else:\n",
    "        data_select.loc[i, 'timeperiod'] = 1\n",
    "\n",
    "# dataFrame column name change\n",
    "data_select.rename(columns={'timeperiod': 'online'}, inplace=True)\n",
    "\n",
    "# Display data for appropriately checking\n",
    "data_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3-2. Deriving Features from Existing Features\n",
    "#### 3-2-1. Make new feature from some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Find the average of the total subject grades\n",
    "data_select['total'] = (data_select['readingscore'] + data_select['writingscore'] + data_select[\n",
    "    'mathscore'] + data_select['readingscoreSL'] + data_select['writingscoreSL'] + data_select[\n",
    "                            'mathscoreSL']) / 6\n",
    "\n",
    "# Each grade data is dropped because the average of the total grade was obtained\n",
    "dropCol = ['readingscore', 'writingscore', 'mathscore', 'readingscoreSL', 'writingscoreSL', 'mathscoreSL', 'covidpos']\n",
    "data_select = data_select.drop(columns=dropCol)\n",
    "\n",
    "data_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a data frame to store grade data according to student data (notOnine, Online)\n",
    "data_transform = (data_select.iloc[:, :11]).copy()\n",
    "data_transform.drop_duplicates(['studentID'], inplace=True)  # Drop rows with duplicate student IDs\n",
    "data_transform.reset_index(inplace=True)  # index reset\n",
    "data_transform.drop(columns=['index'], inplace=True)  # index column 제거\n",
    "\n",
    "# Calculate the average of grades per student (notOnine, Online)\n",
    "for i in range(1, len(data_transform) + 1):\n",
    "    condition0 = (data_select.studentID == i) & (data_select.online == 0)\n",
    "    condition1 = (data_select.studentID == i) & (data_select.online == 1)\n",
    "    temp0 = data_select.loc[condition0]\n",
    "    temp1 = data_select.loc[condition1]\n",
    "    data_transform.loc[i - 1, \"totalNotOnline\"] = (temp0.loc[:, \"total\"].sum() / 3)\n",
    "    data_transform.loc[i - 1, \"totalOnline\"] = (temp1.loc[:, \"total\"].sum() / 3)\n",
    "    data_transform.loc[i - 1, \"differ\"] = data_transform.loc[i - 1, \"totalNotOnline\"] - data_transform.loc[\n",
    "        i - 1, \"totalOnline\"]\n",
    "\n",
    "# Drop onilne column because not using\n",
    "data_transform = data_select.drop(columns=\"online\")\n",
    "\n",
    "# Display data for appropriately checking\n",
    "data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_transform.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3-2-2. Outlier Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def outliars(data, column):\n",
    "    Q1 = np.percentile(data[column], 25)\n",
    "    Q3 = np.percentile(data[column], 75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "    outlier_step = 1.5 * IQR\n",
    "\n",
    "    outliers_index = data[(data[column] < Q1 - outlier_step) | (data[column] > Q3 + outlier_step)].index\n",
    "    return outliers_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#price outlier handling\n",
    "outliers_index = outliars(data_transform, \"differ\")\n",
    "\n",
    "data_transform.drop(outliers_index, inplace=True)\n",
    "data_transform.reset_index(drop=True, inplace=True)\n",
    "data_transform.drop(data_transform[data_transform['differ'] == 0].index, inplace=True)\n",
    "data_transform.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_transform.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3-2-3. Make new feature from 'total' column using clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# K-mean Clustering + Scaling\n",
    "def clustering_scaling(data, i, k, scaler, relationCol, clusterName, xCol, yCol):\n",
    "    data_scale = scaler.fit_transform(data.loc[:, relationCol])  #data scaling\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(data_scale)  # learning scaling data\n",
    "    data[clusterName] = model.fit_predict(data_scale)  # save each clustering data\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    for i in range(k):\n",
    "        plt.scatter(data.loc[data[clusterName] == i, xCol], data.loc[data[clusterName] == i, yCol],\n",
    "                    label=clusterName + str(i))\n",
    "\n",
    "    # make plot graph\n",
    "    plt.legend()\n",
    "    plt.title(str(scaler))\n",
    "    plt.xlabel('totalNotOnline', size=12)\n",
    "    plt.ylabel('totalOnline', size=12)\n",
    "\n",
    "    return plt, data.groupby(clusterName).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_transform_std = data_transform.copy()\n",
    "data_transform_robust = data_transform.copy()\n",
    "data_transform_minmax = data_transform.copy()\n",
    "data_transform_list = [data_transform_std, data_transform_robust, data_transform_minmax]\n",
    "\n",
    "scaler_list = [StandardScaler(), RobustScaler(), MinMaxScaler()]\n",
    "\n",
    "for i in range(3):\n",
    "    plt, groupData = clustering_scaling(data_transform_list[i], i, 3, scaler_list[i],\n",
    "                                        [\"totalNotOnline\", \"totalOnline\", \"differ\"], \"level\",\n",
    "                                        'totalNotOnline', 'differ')\n",
    "\n",
    "    plt.show()\n",
    "    print(groupData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Scaler + SelectKBest\n",
    "def selectKBest_scaling(data, scaler, xCol, yCol):\n",
    "    x = data.loc[:, xCol]  # select using columns\n",
    "    y = data.loc[:, yCol]  # level\n",
    "    scalerTemp = pd.DataFrame(scaler.fit_transform(x))\n",
    "\n",
    "    scalerTemp.columns = [x.columns]\n",
    "\n",
    "    bestfeatures = SelectKBest(score_func=f_regression, k=5)\n",
    "    fit = bestfeatures.fit(x, y)\n",
    "    dfcolumns = pd.DataFrame(x.columns)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Features', 'Score']\n",
    "\n",
    "    return featureScores.nlargest(10, 'Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_columns = [\"school\", \"gender\", \"covidpos\", \"householdincome\", \"freelunch\", \"numcomputers\", \"familysize\", \"fathereduc\", \"mothereduc\", \"totalNotOnline\", \"totalOnline\"]\n",
    "for i in range(3):\n",
    "    print(scaler_list[i])\n",
    "    print(selectKBest_scaling(data_transform_list[i], scaler_list[i], x_columns, \"level\"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(data=data_transform.corr(), annot=True,\n",
    "            fmt='.2f', linewidths=.5, cmap='Blues')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Modeling\n",
    "### 4-1. Linear Regression each scaling & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def linearRegScaling(scaler, k, data, testSize, largeColumns, target):\n",
    "    data_scale = scaler.fit_transform(data.loc[:, largeColumns])  #data scaling\n",
    "\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(data_scale)  # learning scaling data\n",
    "    data['predict'] = model.fit_predict(data_scale)  # save each clustering data\n",
    "\n",
    "    x = data_scale  # school, totalNotOnline columns\n",
    "    y = data.loc[:, target]  # level columns\n",
    "\n",
    "    reg = linear_model.LinearRegression()\n",
    "\n",
    "    # Split the dataset into training and testing\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=testSize, random_state=42, shuffle=True)\n",
    "    reg.fit(x_train, y_train)\n",
    "\n",
    "    # Compute data and find result\n",
    "    resultTrainScore = reg.score(x_train, y_train)\n",
    "    resultTestScore = reg.score(x_test, y_test)\n",
    "\n",
    "    # data collect\n",
    "    return resultTrainScore, resultTestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset train:test & scaler\n",
    "split = [0.1, 0.2, 0.3]\n",
    "scaler = [StandardScaler(), RobustScaler(), MinMaxScaler()]\n",
    "data_transform_list = [data_transform_std, data_transform_robust, data_transform_minmax]\n",
    "largeColumns1 = (\"school\", \"totalNotOnline\")\n",
    "\n",
    "# Create new empty data frame\n",
    "resultBestScaler = pd.DataFrame(index=range(0, 9),\n",
    "                                columns=[\"Scaler\", \"Train\", \"Test\", \"TrainSet Score\", \"TestSet Score\"])\n",
    "\n",
    "j = 0\n",
    "for i in range(len(scaler)):\n",
    "    for k in range(len(split)):\n",
    "        resultTrainScore, resultTestScore = linearRegScaling(scaler[i], 3, data_transform_list[i], split[k],\n",
    "                                                             largeColumns1, \"level\")\n",
    "        resultBestScaler.iloc[j] = [str(scaler[i]), str(1 - split[k]), str(split[k]), resultTrainScore, resultTestScore]\n",
    "        j += 1\n",
    "\n",
    "display(resultBestScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset train:test & scaler\n",
    "split = [0.1, 0.2, 0.3]\n",
    "scaler = [StandardScaler(), RobustScaler(), MinMaxScaler()]\n",
    "\n",
    "# Create new empty data frame\n",
    "resultBestScaler = pd.DataFrame(index=range(0, 9),\n",
    "                                columns=[\"Scaler\", \"Train\", \"Test\", \"TrainSet Score\", \"TestSet Score\"])\n",
    "\n",
    "largeColumns2 = (\"school\", \"totalNotOnline\", \"householdincome\")\n",
    "j = 0\n",
    "for i in range(len(scaler)):\n",
    "    for k in range(len(split)):\n",
    "        resultTrainScore, resultTestScore = linearRegScaling(scaler[i], 3, data_transform_list[i], split[k],\n",
    "                                                             largeColumns2, \"level\")\n",
    "        resultBestScaler.iloc[j] = [str(scaler[i]), str(1 - split[k]), str(split[k]), resultTrainScore, resultTestScore]\n",
    "        j += 1\n",
    "\n",
    "display(resultBestScaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### -> Best Score is RobustScaler Result\n",
    "<br><hr><br>\n",
    "\n",
    "### 4-2. Model Evaluation Metrics for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into 5 subsets of equal size\n",
    "def modelEvaluation(type, largeColumns, target, testSize):\n",
    "    data_scale = data_transform_list[type].loc[:, largeColumns]  #data scaling\n",
    "\n",
    "    x = scaler_list[type].fit_transform(data_scale)  # \"totalNotOnline\", \"totalOnline\" columns data\n",
    "    y = data_transform_list[type].loc[:, target]  # level columns\n",
    "\n",
    "    reg = linear_model.LinearRegression()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=testSize, random_state=42, shuffle=True)\n",
    "    reg.fit(x_train, y_train)\n",
    "    y_pred = pd.DataFrame(reg.predict(x_test))\n",
    "\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(metrics.mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "    return mae, mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create new empty data frame\n",
    "evaluationMetrix = pd.DataFrame(index=range(0, 3),\n",
    "                                columns=[\"Scaler\", \"MAE\", \"MSE\", \"RMSE\"])\n",
    "\n",
    "for i in range(3):  # StandardScaler, RobustScaler, MinMaxScaler\n",
    "    mae, mse, rmse = modelEvaluation(i, largeColumns1, \"level\", 0.2)\n",
    "    evaluationMetrix.iloc[i, :] = [scaler_list[i], mae, mse, rmse]  # Dataframe 데이터 추가\n",
    "\n",
    "display(evaluationMetrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create new empty data frame\n",
    "evaluationMetrix = pd.DataFrame(index=range(0, 3),\n",
    "                                columns=[\"Scaler\", \"MAE\", \"MSE\", \"RMSE\"])\n",
    "\n",
    "for i in range(3):  # StandardScaler, RobustScaler, MinMaxScaler\n",
    "    mae, mse, rmse = modelEvaluation(i, largeColumns2, \"level\", 0.2)\n",
    "    evaluationMetrix.iloc[i, :] = [scaler_list[i], mae, mse, rmse]  # Dataframe 데이터 추가\n",
    "\n",
    "display(evaluationMetrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Learning model evaluation and analysis\n",
    "### 5-1. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confusion_matrix(data_transform_robust.loc[:, \"level\"], data_transform_robust.loc[:, \"predict\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_confusion = {\"Actual\": data_transform_robust.loc[:, \"level\"],\n",
    "                  \"Predict\": data_transform_robust.loc[:, \"predict\"]}\n",
    "dataframe_confusion = pd.DataFrame(data_confusion, columns=[\"Actual\", \"Predict\"])\n",
    "confusion_matrix = pd.crosstab(dataframe_confusion[\"Actual\"], dataframe_confusion[\"Predict\"])\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='.0f', linewidths=.5, cmap='Blues')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def precisionRecall(matrix, column):\n",
    "    precision = np.zeros(len(column))\n",
    "    recall = np.zeros(len(column))\n",
    "    for i in range(len(column)):\n",
    "        precision[i] += matrix.iloc[i, i] / matrix.iloc[:, i].sum()\n",
    "        recall[i] += matrix.iloc[i, i] / matrix.iloc[i, :].sum()\n",
    "\n",
    "    return precision, recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true = np.array(data_transform_robust[\"level\"])\n",
    "y_pred = np.array(data_transform_robust[\"predict\"])\n",
    "confusion_matrix_result = pd.DataFrame(confusion_matrix, columns=[0, 1, 2], index=[0, 1, 2])\n",
    "precision, recall = precisionRecall(confusion_matrix_result, confusion_matrix.columns)\n",
    "\n",
    "print(\"Precision (0): %.2f\" % precision[0])\n",
    "print(\"Precision (1): %.2f\" % precision[1])\n",
    "print(\"Precision (2): %.2f\" % precision[2])\n",
    "print(\"Recall (0): %.2f\" % recall[0])\n",
    "print(\"Recall (1): %.2f\" % recall[1])\n",
    "print(\"Recall (2): %.2f\" % recall[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}